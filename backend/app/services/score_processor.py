import music21
import tempfile
import os
import subprocess
from typing import Dict, Any, List, Optional
import xml.etree.ElementTree as ET
from pathlib import Path
import zipfile
import io


class ScoreProcessor:
    def __init__(self):
        self.supported_formats = ['.xml', '.musicxml', '.mxl', '.mei', '.pdf']
    
    def process_score(self, file_path: str) -> Dict[str, Any]:
        """
        Process score file and return parsed MusicXML data.
        
        Args:
            file_path: Path to the score file
            
        Returns:
            Dictionary containing parsed score data and metadata
        """
        file_ext = Path(file_path).suffix.lower()
        
        if file_ext == '.pdf':
            # Use OMR to convert PDF to MusicXML
            musicxml_path = self._convert_pdf_to_musicxml(file_path)
        elif file_ext == '.mxl':
            # Extract MusicXML from compressed MXL
            musicxml_path = self._extract_mxl(file_path)
        else:
            # Direct MusicXML/MEI processing
            musicxml_path = file_path
        
        # Parse MusicXML
        score_data = self._parse_musicxml(musicxml_path)
        
        # Clean up temporary files
        if file_ext in ['.pdf', '.mxl'] and musicxml_path != file_path:
            os.unlink(musicxml_path)
        
        return score_data
    
    def _convert_pdf_to_musicxml(self, pdf_path: str) -> str:
        """Convert PDF to MusicXML using Audiveris OMR."""
        # Create temporary output directory
        with tempfile.TemporaryDirectory() as temp_dir:
            # Run Audiveris OMR
            cmd = [
                "java", "-Xmx4g", "-jar", "/app/Audiveris-5.6.2/bin/Audiveris-5.6.2.jar",
                "-batch", "-transcribe", "-export",
                "-output", temp_dir,
                pdf_path
            ]
            
            try:
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
                result.check_returncode()
            except subprocess.TimeoutExpired:
                raise Exception("OMR processing timed out")
            except subprocess.CalledProcessError as e:
                raise Exception(f"OMR processing failed: {e.stderr}")
            
            # Find the generated MusicXML file
            musicxml_files = list(Path(temp_dir).glob("*.xml"))
            if not musicxml_files:
                raise Exception("No MusicXML file generated by OMR")
            
            # Copy to a new temporary file (since temp_dir will be deleted)
            output_path = tempfile.mktemp(suffix='.xml')
            import shutil
            shutil.copy2(musicxml_files[0], output_path)
            
            return output_path
    
    def _extract_mxl(self, mxl_path: str) -> str:
        """Extract MusicXML from compressed MXL file."""
        with zipfile.ZipFile(mxl_path, 'r') as zip_ref:
            # Find the MusicXML file in the archive
            xml_files = [f for f in zip_ref.namelist() if f.endswith('.xml')]
            if not xml_files:
                raise Exception("No MusicXML file found in MXL archive")
            
            # Extract the first XML file
            xml_content = zip_ref.read(xml_files[0])
            
            # Write to temporary file
            output_path = tempfile.mktemp(suffix='.xml')
            with open(output_path, 'wb') as f:
                f.write(xml_content)
            
            return output_path
    
    def _parse_musicxml(self, musicxml_path: str) -> Dict[str, Any]:
        """Parse MusicXML file and extract structured data."""
        # Load with music21
        score = music21.converter.parse(musicxml_path)
        
        # Extract basic metadata
        metadata = {
            "title": score.metadata.title or "Untitled",
            "composer": score.metadata.composer or "Unknown",
            "number_of_parts": len(score.parts),
            "number_of_measures": len(score.recurse().getElementsByClass('Measure')),
            "time_signatures": [],
            "key_signatures": [],
            "tempo_markings": []
        }
        
        # Extract time signatures
        for ts in score.recurse().getElementsByClass('TimeSignature'):
            metadata["time_signatures"].append({
                "measure": ts.measureNumber,
                "numerator": ts.numerator,
                "denominator": ts.denominator
            })
        
        # Extract key signatures
        for ks in score.recurse().getElementsByClass('KeySignature'):
            metadata["key_signatures"].append({
                "measure": ks.measureNumber,
                "sharps": ks.sharps
            })
        
        # Extract tempo markings
        for tempo in score.recurse().getElementsByClass('MetronomeMark'):
            metadata["tempo_markings"].append({
                "measure": tempo.measureNumber,
                "number": tempo.number,
                "text": str(tempo)
            })
        
        # Extract notes and measures
        measures_data = []
        for part in score.parts:
            part_data = {
                "part_name": part.partName or f"Part {part.id}",
                "part_id": part.id,
                "measures": []
            }
            
            for measure in part.getElementsByClass('Measure'):
                measure_data = {
                    "measure_number": measure.number,
                    "notes": [],
                    "rests": [],
                    "chords": []
                }
                
                # Extract notes
                for note in measure.recurse().getElementsByClass('Note'):
                    note_data = {
                        "pitch": note.pitch.midi,
                        "pitch_name": note.pitch.nameWithOctave,
                        "duration_quarter_length": float(note.duration.quarterLength),
                        "onset_quarter": float(note.offset),
                        "velocity": 80,  # Default velocity
                        "tie": note.tie is not None
                    }
                    measure_data["notes"].append(note_data)
                
                # Extract rests
                for rest in measure.recurse().getElementsByClass('Rest'):
                    rest_data = {
                        "duration_quarter_length": float(rest.duration.quarterLength),
                        "onset_quarter": float(rest.offset)
                    }
                    measure_data["rests"].append(rest_data)
                
                # Extract chords
                for chord in measure.recurse().getElementsByClass('Chord'):
                    chord_data = {
                        "pitches": [p.midi for p in chord.pitches],
                        "pitch_names": [p.nameWithOctave for p in chord.pitches],
                        "duration_quarter_length": float(chord.duration.quarterLength),
                        "onset_quarter": float(chord.offset),
                        "velocity": 80
                    }
                    measure_data["chords"].append(chord_data)
                
                part_data["measures"].append(measure_data)
            
            measures_data.append(part_data)
        
        return {
            "metadata": metadata,
            "parts": measures_data,
            "musicxml_path": musicxml_path
        }
    
    def convert_to_midi_reference(self, score_data: Dict[str, Any], tempo: float = 120.0) -> List[Dict[str, Any]]:
        """Convert score data to MIDI-like reference sequence for alignment."""
        reference_events = []
        
        # Convert quarter notes to seconds based on tempo
        quarter_to_seconds = 60.0 / tempo
        
        for part in score_data["parts"]:
            current_time = 0.0
            
            for measure in part["measures"]:
                # Process notes
                for note in measure["notes"]:
                    onset_s = current_time + (note["onset_quarter"] * quarter_to_seconds)
                    duration_s = note["duration_quarter_length"] * quarter_to_seconds
                    offset_s = onset_s + duration_s
                    
                    reference_events.append({
                        "pitch": note["pitch"],
                        "onset_s": onset_s,
                        "offset_s": offset_s,
                        "velocity": note["velocity"],
                        "duration_s": duration_s,
                        "measure": measure["measure_number"],
                        "part_id": part["part_id"],
                        "type": "note"
                    })
                
                # Process chords
                for chord in measure["chords"]:
                    onset_s = current_time + (chord["onset_quarter"] * quarter_to_seconds)
                    duration_s = chord["duration_quarter_length"] * quarter_to_seconds
                    offset_s = onset_s + duration_s
                    
                    for pitch in chord["pitches"]:
                        reference_events.append({
                            "pitch": pitch,
                            "onset_s": onset_s,
                            "offset_s": offset_s,
                            "velocity": chord["velocity"],
                            "duration_s": duration_s,
                            "measure": measure["measure_number"],
                            "part_id": part["part_id"],
                            "type": "chord_note"
                        })
                
                # Advance time by measure duration (assuming 4/4 for now)
                current_time += 4.0 * quarter_to_seconds
        
        # Sort by onset time
        reference_events.sort(key=lambda x: x["onset_s"])
        
        return reference_events
